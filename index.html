<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>UAVBench and UAVIT-1M</title>
  <link rel="icon" type="image/x-icon" href="static/images/UAVIT-1M.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"
                        style="display: flex;flex-direction: row;align-items: center;justify-content: center;margin-bottom: 5px;"><img
                            src="./static/images/UAVIT-1M.png" width="80" height="80" style="margin-right: 25px;margin-bottom: 6px;">UAVBench and UAVIT-1M:</h1>
<!--             <h1 class="title is-1 publication-title">UAVBench and UAVIT-1M:</h1> -->
             <h2 class="title is-2 publication-title">A Low-Altitude UAV Vision-Language Benchmark and Instruction-Tuning Dataset for MLLMs</h2>
<!--              <h5 class="subtitle is-5 publication-awards">NeurIPS 2025</h5> -->
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Anonymous Authors</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Anonymous Authors</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Anonymous Authors</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Institution Name</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
<!--                     <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->


                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

           <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                      
            <!-- Dataset Link -->
<!--                <span class="link-block">
                      <a href="https://huggingface.co/datasets/**/***" target="_blank"
                         class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        ðŸ¤—
                      </span>
                      <span>Space</span>
                    </a>
                  </span> -->
              <span class="link-block">
                  <a href="https://huggingface.co/datasets/ZhanYang-nwpu/UAVBench" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-database"></i>
                    </span>
                    <span>UAVBench</span>
                  </a>
                </span>
             <span class="link-block">
                  <a href="https://huggingface.co/datasets/ZhanYang-nwpu/UAVIT-1M" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-database"></i>
                    </span>
                    <span>UAVIT-1M</span>
                  </a>
                </span>
             
      
                  <!-- Model Link -->
                <span class="link-block">
                  <a href="https://huggingface.co/collections/ZhanYang-nwpu/uavmllm-6822afcc022ead749dab62ec" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-share-square"></i>
                    </span>
                    <span>Model</span>
                  </a>
                </span>
            </div>
   
                    
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


  
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h4 class="subtitle has-text-centered">
          ðŸŽ‰ðŸŽ‰ðŸŽ‰<span style="color: #ff3860">[NEW!]</span> This is the first vision-language benchmark, instruction tuning dataset, and multi-modal large language model baseline, specifically tailored to low-altitude UAV scenarios.
          <br><br>
          The web page project is under construction...
        </h4>

         <br>
        <div class="columns is-centered">
            <div class="column has-text-centered">
           <font size="5">
               <br>ðŸ“¢<b>What's New</b>
            </font>
                            <font size="4">
                  <table width="90%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
                    <tr>
                      <td>
                        <div  align="left" style="height: 150px; overflow: auto;">
                          <ul>
<!--                         <li> <span style="color: red; font-weight: bold;">[2024.09.26] ShareGPT4Video is accepted by NeurIPS 2024 D&B Track! ðŸŽ‰ðŸŽ‰ðŸŽ‰</span> -->
                            <li> <span style="color: red; font-weight: bold;"> This is an ongoing project. We will be working on improving it. </span>
                            <li> <b style="color:#E68E34">[2025......]</b> The complete evaluation code is coming soon!
                            <li> <b style="color:#E68E34">[2025......]</b> The detailed low-altitude UAV MLLMs model inference tutorial is coming soon!
<!--                             <li> <b style="color:#E68E34">[2025.05.15]</b> ðŸ”¥ <b>Project Page</b> is released!</b> -->
                            <li> <b style="color:#E68E34">[2025.05.13]</b> ðŸ”¥ 3 low-altitude UAV Multi-modal Large Language Model baselines are released!</b>
                            <li> <b style="color:#E68E34">[2025.05.13]</b> The <b>GeoChat-UAV</b> model is released!
                            <li> <b style="color:#E68E34">[2025.05.13]</b> The <b>MiniGPTv2-UAV</b> model is released!
                            <li> <b style="color:#E68E34">[2025.05.13]</b> The <b>LLaVA1.5-UAV</b> model is released!
                            <li> <b style="color:#E68E34">[2025.05.13]</b> ðŸ”¥ <b>UAVBench benchmark and UAVIT-1M instruct tunning Dataset</b> are released!</b>
                          </ul>
                        </div>
                      </td>
                    </tr>
                  </tbody></table>
                </font>

              </div>
               </div>
        
      </div>
    </div>
  </section>


  


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
<!--       <div class="column is-four-fifths"> -->
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Multimodal Large Language Models (MLLMs) have made significant strides in natural images and satellite remote sensing images, 
            allowing humans to hold a meaningful dialogue based on given visual content. 
            However, understanding low-altitude drone scenarios remains a challenge, even for advanced MLLMs. 
            Existing benchmarks primarily focus on a few specific low-altitude visual tasks, which cannot fully assess the ability of MLLMs in real-world low-altitude UAV applications. 
            Therefore, we introduce <b>UAVBench</b>, a comprehensive benchmark, and <b>UAVIT-1M</b>, a large-scale instruction tuning dataset, 
            designed to evaluate and improve MLLMs' abilities in low-altitude UAV visual and vision-language tasks. 
            UAVBench comprises <b>43 test units</b> and <b>966k high-quality data samples</b> across <b>10 tasks</b> at the image-level and region-level. 
            UAVIT-1M consists of approximately <b>1.24 million diverse instructions</b>, covering <b>789k multi-scene low-altitude UAV images</b> and about <b>2,000 types of spatial resolutions</b> with <b>11 distinct tasks</b>, i.e, image/region classification, image/region captioning, VQA, object detection, visual grounding, etc. 
            UAVBench and UAVIT-1M feature pure real-world visual images and rich weather conditions, and involve manual sampling verification to ensure high quality. 
            Our in-depth analysis of <b>10 state-of-the-art MLLMs</b> using UAVBench reveals that existing MLLMs cannot generate accurate conversations about low-altitude visual content. 
            Extensive experiments demonstrate that fine-tuning MLLMs on UAVIT-1M significantly addresses this gap. 
            Our contributions pave the way for bridging the gap between current MLLMs and low-altitude UAV real-world application demands.
          </p>
        </div>
            <div class="content has-text-justified">
                    <img class="columns is-centered has-text-centered" src="./static/images/0-intro.png" alt="Teaser" width="100%"
                         style="margin:0 auto">
                    <br>
                    <figcaption>
                        <p style="text-align: center;">
                            <font color="061E61">
                                <b>Figure 1:</b> UAVIT-1M supports 11 distinct tasks, spanning visual comprehension to vision-language reasoning, from image level to region level.
                            </font>
                        </p>
                    </figcaption>
            </div>
        
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



  
<!-- Dataset -->
<section class="section">
    <div class="container is-max-desktop">

        <div class="columns is-centered has-text-centered">
            <h2 class="title is-2">
              <img src="./static/images/UAVIT-1M.png" style="width:12%;vertical-align: middle" alt="Logo"/>
          <span style="vertical-align: middle">UAVBench and UAVIT-1M</span>
              
            </h2>
            <br>
        </div>

       <!-- Object Category -->
      <div class="columns is-centered">
            <div class="column is-full-width">
                <h4 class="title is-4">â€¢ Object Category </h4>
                   <div class="content has-text-justified">
                    <img class="columns is-centered has-text-centered" src="./static/images/2-dataanali.png" alt="Teaser" width="95%"
                         style="margin:0 auto"> 
                      <br>
                    <figcaption>
                        <p style="text-align: center;">
                            <font color="061E61">
                                <b>Figure 2:</b> Category distribution in each task. Zoom in to view the specific categories and corresponding quantities.
                            </font>
                        </p>
                    </figcaption>
                    </div>
           </div>
       </div>



                   <!-- VQA + RVQA -->
         <div class="columns is-centered">
            <div class="column is-full-width">
                <h4 class="title is-4">â€¢ Question Types of VQA Task </h4>
                   <div class="content has-text-justified">
                    <img class="columns is-centered has-text-centered" src="./static/images/2-dataanali3.png" alt="Teaser" width="95%"
                         style="margin:0 auto"> 
                      <br>
                    <figcaption>
                        <p style="text-align: center;">
                            <font color="061E61">
                                <b>Figure 3:</b> Distribution of question types in image-level and region-level VQA tasks of UAVBench and UAVIT-1M.
                            </font>
                        </p>
                    </figcaption>
                    </div>
            </div>
          </div>



                         <!-- object size  counting  difficulty  -->
         <div class="columns is-centered">
            <div class="column is-full-width">
                <h4 class="title is-4">â€¢ Distribution of Object Size and Target Counting Difficulty  </h4>
                   <div class="content has-text-justified">
                    <img class="columns is-centered has-text-centered" src="./static/images/2-dataanali4.png" alt="Teaser" width="95%"
                         style="margin:0 auto"> 
                      <br>
                    <figcaption>
                        <p style="text-align: center;">
                            <font color="061E61">
                                <b>Figure 4:</b> (a) Distribution of object sizes in all region-level tasks. (b) Distribution of difficulty in the target counting task.
                            </font>
                        </p>
                    </figcaption>
                    </div>
            </div>
          </div>



          
             <!-- Resolution Position -->
       <div class="columns is-centered">
            <div class="column is-full-width">
                <h4 class="title is-4">â€¢ Spatial Resolution of Image and Distribution of Object Position </h4>
                   <div class="content has-text-justified">
                    <img class="columns is-centered has-text-centered" src="./static/images/2-dataanali2.png" alt="Teaser" width="95%"
                         style="margin:0 auto"> 
                      <br>
                    <figcaption>
                        <p style="text-align: center;">
                            <font color="061E61">
                                <b>Figure 5:</b> Image resolution and target position distributions in UAVIT1M. Best viewed by zooming in.
                            </font>
                        </p>
                    </figcaption>
                    </div>
               <br/>
           </div>
        </div>

      

      
    </div>
</section>
<!-- End Dataset -->
  

  
<!-- Result Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
<!--     <div class="container"> -->
    <div class="container is-max-desktop">
       <div class="column is-full-width">

        <div class="columns is-centered has-text-centered">
            <h2 class="title is-2">Qualitative Comparisons</h2>
            <br>
        </div>
         
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/6-imagecls.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Qualitative comparisons in the task of image classification.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/7-imagedcls.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Qualitative comparisons in the task of detailed classification.
        </h2>
      </div>
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/8-imagecount.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Qualitative comparisons in the task of target counting.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/9-imagecap.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
        Qualitative comparisons in the task of image captioning.
       </h2>
     </div>
              <div class="item">
        <!-- Your image here -->
        <img src="static/images/10-imagevqa.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
        Qualitative comparisons in the task of visual question answering.
       </h2>
     </div>
              <div class="item">
        <!-- Your image here -->
        <img src="static/images/11-regionvqa.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
       Qualitative comparisons in the task of region visual question answering.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/12-regioncap.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Qualitative comparisons in the task of region caption.
      </h2>
    </div>
                      <div class="item">
        <!-- Your image here -->
        <img src="static/images/13-regioncls.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
       Qualitative comparisons in the task of region classification.
       </h2>
     </div>
                      <div class="item">
        <!-- Your image here -->
        <img src="static/images/15-regiondet.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
       Qualitative comparisons in the task of region detection.
       </h2>
     </div>
                              <div class="item">
        <!-- Your image here -->
        <img src="static/images/15-regiondet2.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
       Qualitative comparisons in the task of region detection.
       </h2>
     </div>
                              <div class="item">
        <!-- Your image here -->
        <img src="static/images/14-regionvg.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
       Qualitative comparisons in the task of visual grounding.
       </h2>
     </div>
  </div>
     </div>
</div>
</div>
</section>
<!-- End image carousel -->










<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
       <h2 class="title is-3 has-text-centered">ðŸ“ƒ BibTeX</h2>
<!--       <h2 class="title">BibTeX</h2> -->
      <pre><code>
@article{2025uavbench,
  title={{UAVBench and UAVIT-1M}: A Low-Altitude UAV Vision-Language Benchmark and Instruction-Tuning Dataset for MLLMs},
  author={},
  journal={},
  year={2025}
}
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  

<section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgement</h2>
          <p>
            This website is adapted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page, licensed under a <a rel="license"  
                                                                                                                                              href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

  </div>
</section>


      <footer class="footer">
        <div class="columns is-centered has-text-centered">
        <div class="column is-8">
<!--           <div class="content"> -->
            <centering>
              <div style="width: 40%; text-align: center;">
               <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=AiCP80arppGBS7PEsw1QmWoLG-mSNmKDaNN-l7pfiYw&cl=ffffff&w=a"></script>
              </div>
            </centering>
<!--           </div> -->
        </div>
      </div>
    </footer>
  

  
<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
